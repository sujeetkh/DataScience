{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/softs/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/admin/softs/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#train data\n",
    "revenue_train=pd.read_csv('patient_monthwise_revenue_train.csv')\n",
    "diagnosis_train=pd.read_csv('physio_diagnosis_train.csv')\n",
    "classified_train=pd.read_csv('patient_train_classified.csv')\n",
    "appts_train=pd.read_csv('physio_appts_train.csv')\n",
    "#test data\n",
    "revenue_test=pd.read_csv('patient_monthwise_revenue_test.csv')\n",
    "diagnosis_test=pd.read_csv('physio_diagnosis_test.csv')\n",
    "submission=pd.read_csv('Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def avg_nps_val(val1 , val2):\n",
    "    if is_number(val1):\n",
    "        return val1\n",
    "    if is_number(val2):\n",
    "        return val2\n",
    "    return 0.0\n",
    "\n",
    "def diag_val(diag,nps,un):\n",
    "    val=str(diag)\n",
    "    if not nps.isdigit() and not nps=='nan':\n",
    "        val=val+' '+ nps\n",
    "    if not un.isdigit() and not un=='nan':\n",
    "        val=val+' '+un\n",
    "    return val\n",
    "\n",
    "def get_month(val):\n",
    "    return int(str(val).strip()[:2])\n",
    "\n",
    "def get_year(val):\n",
    "    return int(str(val).strip()[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient_id', 'visit_month_year', 'service_id', 'visits_count', 'city', 'revenue', 'ref_type', 'ref_name', 'ref_source', 'service_name', 'FVD', 'FVM', 'FVS', 'approx_age', 'gender', 'LVD', 'brand', 'visits_required', 'diagnosis', 'avg_nps', 'Unnamed: 20', 'Unnamed: 21']\n",
      "['patient_id', 'visit_month_year', 'service_id', 'city', 'ref_type', 'ref_name', 'ref_source', 'service_name', 'FVD', 'FVM', 'FVS', 'approx_age', 'gender', 'LVD', 'brand', 'visits_required', 'diagnosis', 'avg_nps', 'Unnamed: 18', 'Unnamed: 19']\n"
     ]
    }
   ],
   "source": [
    "print list(revenue_train)\n",
    "print list(revenue_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revenue_train[['FVD', 'FVM', 'FVS','LVD']].head()\n",
    "revenue_train['is_recurring']=revenue_train.apply(lambda row: 1 if str(row['FVD'])==str(row['LVD']) else 0, axis=1)\n",
    "revenue_test['is_recurring']=revenue_train.apply(lambda row: 1 if str(row['FVD'])==str(row['LVD']) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_train.drop(['FVD', 'FVM', 'FVS','LVD'],axis = 1, inplace=True)\n",
    "revenue_test.drop(['FVD', 'FVM', 'FVS','LVD'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in revenue_train.columns.values:\n",
    "    if revenue_train[col].dtypes=='object':\n",
    "        revenue_train[col]=revenue_train[col].str.replace('\\N','')\n",
    "        \n",
    "for col in revenue_test.columns.values:\n",
    "    if revenue_test[col].dtypes=='object':\n",
    "        revenue_test[col]=revenue_test[col].str.replace('\\N','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in revenue_train.columns.values:\n",
    "    if revenue_train[col].dtypes=='object':\n",
    "        revenue_train[col]=revenue_train[col].str.replace('\\\\','')\n",
    "        \n",
    "for col in revenue_test.columns.values:\n",
    "    if revenue_test[col].dtypes=='object':\n",
    "        revenue_test[col]=revenue_test[col].str.replace('\\\\','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_train['diagnosis']=revenue_train.apply(lambda row:diag_val(row['diagnosis'],str(row['avg_nps']),str(row['Unnamed: 20'])), axis=1)\n",
    "revenue_test['diagnosis']=revenue_test.apply(lambda row:diag_val(row['diagnosis'],str(row['avg_nps']),str(row['Unnamed: 18'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['avg_nps']=revenue_train.apply(lambda row: avg_nps_val(row['avg_nps'],row['Unnamed: 20']), axis=1)\n",
    "revenue_test['avg_nps']=revenue_test.apply(lambda row: avg_nps_val(row['avg_nps'],row['Unnamed: 18']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['avg_nps']=revenue_train['avg_nps'].astype('float')\n",
    "revenue_test['avg_nps']=revenue_test['avg_nps'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['avg_nps']=revenue_train['avg_nps'].fillna(0.0)\n",
    "revenue_test['avg_nps']=revenue_test['avg_nps'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83307 entries, 0 to 83306\n",
      "Data columns (total 19 columns):\n",
      "patient_id          83307 non-null int64\n",
      "visit_month_year    83307 non-null object\n",
      "service_id          83307 non-null int64\n",
      "visits_count        83307 non-null int64\n",
      "city                83307 non-null object\n",
      "revenue             83307 non-null float64\n",
      "ref_type            83307 non-null object\n",
      "ref_name            83307 non-null object\n",
      "ref_source          83307 non-null object\n",
      "service_name        82084 non-null object\n",
      "approx_age          83307 non-null object\n",
      "gender              83274 non-null object\n",
      "brand               83307 non-null object\n",
      "visits_required     83307 non-null int64\n",
      "diagnosis           83307 non-null object\n",
      "avg_nps             83307 non-null float64\n",
      "Unnamed: 20         36 non-null object\n",
      "Unnamed: 21         16 non-null object\n",
      "is_recurring        83307 non-null int64\n",
      "dtypes: float64(2), int64(5), object(12)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "revenue_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_train.drop([ 'Unnamed: 20', 'Unnamed: 21'],axis = 1, inplace=True)\n",
    "revenue_test.drop(['Unnamed: 18', 'Unnamed: 19'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['visit_month']=revenue_train['visit_month_year'].apply(lambda x: get_month(x))\n",
    "revenue_test['visit_month']=revenue_test['visit_month_year'].apply(lambda x: get_month(x))\n",
    "revenue_train['visit_year']=revenue_train['visit_month_year'].apply(lambda x: get_year(x) )\n",
    "revenue_test['visit_year']=revenue_test['visit_month_year'].apply(lambda x: get_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_train['visit_month']=revenue_train['visit_month'].astype('int')\n",
    "revenue_test['visit_month']=revenue_test['visit_month'].astype('int')\n",
    "revenue_train['visit_year']=revenue_train['visit_year'].astype('int')\n",
    "revenue_test['visit_year']=revenue_test['visit_year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train.drop(['visit_month_year'],axis = 1, inplace=True)\n",
    "revenue_test.drop(['visit_month_year'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref_type,visit_month_year\n",
    "revenue_train['approx_age']=revenue_train['approx_age'].apply(lambda x: x if is_number(x) else None)\n",
    "revenue_train['approx_age']=revenue_train['approx_age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_test['approx_age']=revenue_test['approx_age'].apply(lambda x: x if is_number(x) else None)\n",
    "revenue_test['approx_age']=revenue_test['approx_age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean=revenue_train['approx_age'].mean()\n",
    "revenue_train['approx_age']=revenue_train['approx_age'].fillna(mean)\n",
    "mean=revenue_test['approx_age'].mean()\n",
    "revenue_test['approx_age']=revenue_test['approx_age'].fillna(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_test['is_male']=revenue_test['gender'].apply(lambda x: 2 if str(x)=='male' else 1)\n",
    "revenue_train['is_male']=revenue_train['gender'].apply(lambda x: 2 if str(x)=='male' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train.drop(['gender'],axis = 1, inplace=True)\n",
    "revenue_test.drop(['gender'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_test['is_ref_type_b2c']=revenue_test['ref_type'].apply(lambda x: 2 if str(x)=='B2C' else 1)\n",
    "revenue_train['is_ref_type_b2c']=revenue_train['ref_type'].apply(lambda x: 2 if str(x)=='B2C' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train.drop(['ref_type'],axis = 1, inplace=True)\n",
    "revenue_test.drop(['ref_type'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['diagnosis']=revenue_train['diagnosis'].astype('string')\n",
    "revenue_train['word_count'] = revenue_train['diagnosis'].apply(lambda x: len(str(x).split(\" \")))\n",
    "revenue_test['diagnosis']=revenue_test['diagnosis'].astype('string')\n",
    "revenue_test['word_count'] = revenue_test['diagnosis'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['char_count'] = revenue_train['diagnosis'].str.len()\n",
    "revenue_test['char_count'] = revenue_test['diagnosis'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    try:\n",
    "        words = sentence.split()\n",
    "        return (sum(len(word) for word in words)/len(words))\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "revenue_train['avg_word'] = revenue_train['diagnosis'].apply(lambda x: avg_word(x))\n",
    "revenue_test['avg_word'] = revenue_test['diagnosis'].apply(lambda x: avg_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/softs/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:3: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/admin/softs/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:4: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "revenue_train['stopwords'] = revenue_train['diagnosis'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "revenue_test['stopwords'] = revenue_test['diagnosis'].apply(lambda x: len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['numerics'] = revenue_train['diagnosis'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "revenue_test['numerics'] = revenue_test['diagnosis'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['upper'] = revenue_train['diagnosis'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "revenue_test['upper'] = revenue_test['diagnosis'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['diagnosis'] = revenue_train['diagnosis'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "revenue_test['diagnosis'] = revenue_test['diagnosis'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "revenue_train['diagnosis'] = revenue_train['diagnosis'].str.replace('[^\\w\\s]','')\n",
    "revenue_test['diagnosis'] = revenue_test['diagnosis'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "revenue_train['diagnosis'] = revenue_train['diagnosis'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "revenue_test['diagnosis'] = revenue_test['diagnosis'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "revenue_train['diagnosis'] = revenue_train['diagnosis'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "revenue_test['diagnosis'] = revenue_test['diagnosis'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_train.drop(['visits_count', 'revenue'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/softs/anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:216: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "/Users/admin/softs/anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:275: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in revenue_train.columns.values:\n",
    "    if revenue_train[col].dtypes=='object':\n",
    "        data=revenue_train[col].append(revenue_test[col])\n",
    "        le.fit(data.values)\n",
    "        revenue_train[col]=le.transform(revenue_train[col])\n",
    "        revenue_test[col]=le.transform(revenue_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_train.rename(columns={'PID': 'patient_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.merge(revenue_train,classified_train,how='left',on='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=train_data[['patient_id','Bucket','Revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.drop(['patient_id','Bucket','Revenue'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pat_ids=revenue_test['patient_id']\n",
    "test_data=revenue_test\n",
    "test_data.drop(['patient_id'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83307 entries, 0 to 83306\n",
      "Data columns (total 21 columns):\n",
      "service_id         83307 non-null int64\n",
      "city               83307 non-null int64\n",
      "ref_name           83307 non-null int64\n",
      "ref_source         83307 non-null int64\n",
      "service_name       83307 non-null int64\n",
      "approx_age         83307 non-null float64\n",
      "brand              83307 non-null int64\n",
      "visits_required    83307 non-null int64\n",
      "diagnosis          83307 non-null int64\n",
      "avg_nps            83307 non-null float64\n",
      "is_recurring       83307 non-null int64\n",
      "visit_month        83307 non-null int64\n",
      "visit_year         83307 non-null int64\n",
      "is_male            83307 non-null int64\n",
      "is_ref_type_b2c    83307 non-null int64\n",
      "word_count         83307 non-null int64\n",
      "char_count         83307 non-null int64\n",
      "avg_word           83307 non-null int64\n",
      "stopwords          83307 non-null int64\n",
      "numerics           83307 non-null int64\n",
      "upper              83307 non-null int64\n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 14.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def random_forest(train_x,train_y,test_x,test_y):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(train_x, train_y)\n",
    "    prediction=clf.predict(test_x)\n",
    "    print accuracy_score(test_y,prediction)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost(train_x, train_y, test_x, test_y):\n",
    "    clf=xgb.XGBClassifier(max_depth=5, n_estimators=300, learning_rate=0.03)\n",
    "    clf.fit(train_x, train_y)\n",
    "    prediction = clf.predict(test_x)\n",
    "    print accuracy_score(test_y,prediction)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.drop(['Bucket'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y =train_test_split(train_data, y_val['Bucket'], test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685631976954\n"
     ]
    }
   ],
   "source": [
    "rf_clf=xgboost(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867302844797\n"
     ]
    }
   ],
   "source": [
    "f_clf=random_forest(train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=f_clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({ 'PID': pat_ids,'Bucket': res })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = sub.groupby('PID')\n",
    "p_id=[]\n",
    "bucket=[]\n",
    "for name, group in grouped:\n",
    "   # print(name)\n",
    "    low=0\n",
    "    mid=0\n",
    "    high=0\n",
    "    high_med=0\n",
    "    for val in group['Bucket']:\n",
    "        if str(val)==\"Low\":\n",
    "            low=low+1\n",
    "        elif str(val)==\"Med\":\n",
    "            mid=mid+1\n",
    "        elif str(val)==\"High\":\n",
    "            high=high+1\n",
    "        else:\n",
    "            high_med=high_med+1\n",
    "    \n",
    "    p_id.append(name) \n",
    "    \n",
    "    if high>0:\n",
    "        bucket.append(\"High\")\n",
    "    elif high_med>0:\n",
    "        bucket.append(\"High-Med\")\n",
    "    elif mid>0:\n",
    "        bucket.append(\"Med\")\n",
    "    else:\n",
    "        bucket.append(\"Low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame({ 'PID': p_id,'Bucket': bucket })\n",
    "final=pd.merge(submission,subm,how='left',on='PID')\n",
    "final[['PID','Bucket']].to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y =train_test_split(train_data, y_val['Revenue'], test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T_train_xgb = xgb.DMatrix(train_x, train_y)\n",
    "#params = {\"objective\": \"reg:linear\", \"booster\":\"gblinear\"}\n",
    "#gbm = xgb.train(dtrain=T_train_xgb,params=params)\n",
    "#res = gbm.predict(xgb.DMatrix(test_data))\n",
    "#print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred = lreg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse = np.mean((pred - test_y)**2)\n",
    "#print mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X = poly.fit_transform(train_data)\n",
    "T = poly.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55329, 253)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= y_val['Revenue'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(fit_intercept=False, max_iter=10, tol=None,shuffle=False).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logisticRegr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=logisticRegr.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({ 'PID': pat_ids,'Bucket': res })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3681.766624     7\n",
       "-2137.551542     5\n",
       "-2178.879860     5\n",
       "-1814.883375     4\n",
       " 2088.907418     3\n",
       "-5817.003354     3\n",
       "-8018.781694     3\n",
       " 4055.053200     3\n",
       "-3997.711580     3\n",
       " 3079.935683     2\n",
       " 28901.454086    2\n",
       " 6889.443776     2\n",
       " 3439.977951     2\n",
       " 6058.834574     2\n",
       " 13067.887736    2\n",
       " 1650.421651     2\n",
       " 7242.754243     2\n",
       " 10109.772668    2\n",
       " 1363.461855     2\n",
       "-2548.436180     2\n",
       "-1750.667666     2\n",
       "-1096.007622     2\n",
       " 3395.196300     2\n",
       " 18456.197975    2\n",
       " 17134.449018    2\n",
       " 3926.267012     2\n",
       "-5364.294597     2\n",
       " 18521.015521    2\n",
       "-6837.359181     2\n",
       "-2663.510474     2\n",
       "                ..\n",
       " 14661.858895    1\n",
       " 57897.625120    1\n",
       " 15197.699278    1\n",
       " 7793.229749     1\n",
       "-681.782581      1\n",
       " 16233.577240    1\n",
       " 21537.374201    1\n",
       " 1603.697440     1\n",
       " 3536.808150     1\n",
       " 19502.779764    1\n",
       "-7595.671203     1\n",
       " 56686.178258    1\n",
       "-2643.107128     1\n",
       " 43479.040337    1\n",
       " 3509.309232     1\n",
       " 11820.226318    1\n",
       " 16059.206964    1\n",
       " 3685.292385     1\n",
       " 3761.158720     1\n",
       " 16079.122122    1\n",
       " 32815.261784    1\n",
       " 3711.292714     1\n",
       " 12353.348073    1\n",
       "-1683.620831     1\n",
       "-14542.861577    1\n",
       " 265.901536      1\n",
       " 11258.820933    1\n",
       " 5444.395936     1\n",
       " 3379.194102     1\n",
       " 16370.021610    1\n",
       "Name: Bucket, Length: 55234, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['Bucket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = sub.groupby('PID')\n",
    "p_id=[]\n",
    "bucket=[]\n",
    "for name, group in grouped:\n",
    "   # print(name)\n",
    "    low=0\n",
    "    mid=0\n",
    "    high=0\n",
    "    high_med=0\n",
    "    for val in group['Bucket']:\n",
    "        if val >10000:\n",
    "            high=high+1\n",
    "        elif val>5000:\n",
    "            high_med=high_med+1 \n",
    "        elif val>1000:\n",
    "            mid=mid+1\n",
    "        else: \n",
    "            low=low+1\n",
    "    \n",
    "    p_id.append(name) \n",
    "    \n",
    "    if high>0:\n",
    "        bucket.append(\"High\")\n",
    "    elif high_med>0:\n",
    "        bucket.append(\"High-Med\")\n",
    "    elif mid>0:\n",
    "        bucket.append(\"Med\")\n",
    "    else:\n",
    "        bucket.append(\"Low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = pd.DataFrame({ 'PID': p_id,'Bucket': bucket })\n",
    "final=pd.merge(submission,subm,how='left',on='PID')\n",
    "final[['PID','Bucket']].to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    '''if high>=low and high>=mid and high>= high_med:\n",
    "        bucket.append(\"High\")\n",
    "    elif high_med>=low and high_med>=mid and high_med>=high:\n",
    "        bucket.append(\"High-Med\")\n",
    "    elif mid>=low and mid>=high_med and mid>=high :\n",
    "        bucket.append(\"Med\")\n",
    "    else:\n",
    "        bucket.append(\"Low\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
